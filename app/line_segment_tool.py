import sys
import cv2
import numpy as np
from PyQt6.QtWidgets import (QApplication, QMainWindow, QWidget, QVBoxLayout,
                             QHBoxLayout, QPushButton, QLabel, QFileDialog,
                             QCheckBox, QSlider, QSpinBox, QGroupBox,
                             QTextEdit, QSplitter, QMessageBox, QComboBox,
                             QTabWidget, QProgressBar)
from PyQt6.QtCore import Qt, QThread, pyqtSignal, QTimer
from PyQt6.QtGui import QPixmap, QImage
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from matplotlib.patches import Polygon
from dataclasses import dataclass
from typing import List, Tuple, Optional, Dict
import json
from scipy import optimize
from scipy.spatial import distance
import warnings

warnings.filterwarnings('ignore')

# æ¨™æº–çƒå ´æ¨¡å‹å®šç¾©
COURT_MODELS = {
    "ç±ƒçƒå ´": {
        "width": 28.0,  # å…¬å°º
        "height": 15.0,
        "key_points": [
            {"name": "ä¸­ç·š", "type": "line", "coords": [(0, 7.5), (28, 7.5)]},
            {"name": "ä¸‰åˆ†ç·š", "type": "arc", "radius": 6.75},
            {"name": "ç½°çƒç·š", "type": "line", "coords": [(5.8, 4.9), (5.8, 10.1)]},
            {"name": "åº•ç·š", "type": "line", "coords": [(0, 0), (28, 0)]},
        ],
        "court_color": (150, 111, 51)  # å…¸å‹æœ¨åœ°æ¿é¡è‰²
    },
    "ç¶²çƒå ´": {
        "width": 23.77,
        "height": 10.97,
        "key_points": [
            {"name": "åº•ç·š", "type": "line", "coords": [(0, 0), (23.77, 0)]},
            {"name": "ç™¼çƒç·š", "type": "line", "coords": [(5.485, 0), (5.485, 10.97)]},
            {"name": "ä¸­ç·š", "type": "line", "coords": [(11.885, 0), (11.885, 10.97)]},
            {"name": "å–®æ‰“é‚Šç·š", "type": "line", "coords": [(0, 1.37), (23.77, 1.37)]},
        ],
        "court_color": (0, 119, 51)  # ç¶ è‰²
    },
    "ç¾½çƒå ´": {
        "width": 13.4,
        "height": 6.1,
        "key_points": [
            {"name": "å‰ç™¼çƒç·š", "type": "line", "coords": [(1.98, 0), (1.98, 6.1)]},
            {"name": "å¾Œç™¼çƒç·šé›™æ‰“", "type": "line", "coords": [(0.76, 0), (0.76, 6.1)]},
            {"name": "ä¸­ç·š", "type": "line", "coords": [(0, 3.05), (13.4, 3.05)]},
        ],
        "court_color": (34, 139, 34)  # ç¶ è‰²
    },
    "è¶³çƒå ´": {
        "width": 105.0,
        "height": 68.0,
        "key_points": [
            {"name": "ä¸­ç·š", "type": "line", "coords": [(52.5, 0), (52.5, 68)]},
            {"name": "ä¸­åœˆ", "type": "circle", "center": (52.5, 34), "radius": 9.15},
            {"name": "ç¦å€", "type": "rect", "coords": [(0, 13.84), (16.5, 54.16)]},
        ],
        "court_color": (0, 128, 0)  # è‰ç¶ è‰²
    }
}


@dataclass
class CourtDetectionResults:
    """å„²å­˜çƒå ´è¾¨è­˜çµæœ"""
    original_image: np.ndarray
    court_mask: Optional[np.ndarray] = None
    court_type: Optional[str] = None
    edge_map: Optional[np.ndarray] = None
    detected_lines: Optional[np.ndarray] = None
    line_intersections: Optional[List[Tuple[int, int]]] = None
    harris_corners: Optional[np.ndarray] = None
    homography_matrix: Optional[np.ndarray] = None
    rectified_court: Optional[np.ndarray] = None
    confidence_score: float = 0.0
    matched_keypoints: Optional[List] = None


class MockMaskRCNN:
    """æ¨¡æ“¬ Mask R-CNN çš„çƒå ´åˆ†å‰²ï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰ä½¿ç”¨çœŸå¯¦çš„é è¨“ç·´æ¨¡å‹ï¼‰"""

    @staticmethod
    def segment_court(image: np.ndarray, court_type: str = "auto") -> tuple:
        """
        æ¨¡æ“¬çƒå ´å€åŸŸåˆ†å‰²
        å¯¦éš›æ‡‰ç”¨ä¸­æ‡‰è©²è¼‰å…¥é è¨“ç·´çš„ Mask R-CNN æ¨¡å‹

        Returns:
            (mask, court_type, confidence)
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

        # ä½¿ç”¨é¡è‰²å’Œé‚Šç·£ç‰¹å¾µä¾†æ¨¡æ“¬åˆ†å‰²
        # å¯¦éš›ä¸Šé€™è£¡æ‡‰è©²æ˜¯æ·±åº¦å­¸ç¿’æ¨¡å‹

        # ç°¡åŒ–ç‰ˆï¼šä½¿ç”¨é¡è‰²é–¾å€¼å’Œå½¢æ…‹å­¸æ“ä½œ
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

        # æª¢æ¸¬ä¸åŒé¡è‰²çš„çƒå ´
        court_masks = {}

        # ç±ƒçƒå ´ï¼ˆæœ¨åœ°æ¿è‰²ï¼‰
        lower_brown = np.array([10, 50, 50])
        upper_brown = np.array([25, 255, 255])
        court_masks["ç±ƒçƒå ´"] = cv2.inRange(hsv, lower_brown, upper_brown)

        # ç¶²çƒå ´/ç¾½çƒå ´ï¼ˆç¶ è‰²ï¼‰
        lower_green = np.array([35, 50, 50])
        upper_green = np.array([85, 255, 255])
        court_masks["ç¶²çƒå ´"] = cv2.inRange(hsv, lower_green, upper_green)

        # é¸æ“‡æœ€å¤§çš„é€£é€šå€åŸŸä½œç‚ºçƒå ´
        best_mask = None
        best_area = 0
        detected_type = "æœªçŸ¥"

        for court_type, mask in court_masks.items():
            # å½¢æ…‹å­¸æ“ä½œæ¸…ç†é›œè¨Š
            kernel = np.ones((5, 5), np.uint8)
            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)

            # æ‰¾æœ€å¤§é€£é€šå€åŸŸ
            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            if contours:
                largest_contour = max(contours, key=cv2.contourArea)
                area = cv2.contourArea(largest_contour)

                if area > best_area and area > image.shape[0] * image.shape[1] * 0.1:
                    best_area = area
                    best_mask = np.zeros_like(mask)
                    cv2.drawContours(best_mask, [largest_contour], -1, 255, -1)
                    detected_type = court_type

        # è¨ˆç®—ç½®ä¿¡åº¦ï¼ˆåŸºæ–¼é¢ç©å’Œå½¢ç‹€è¦å‰‡æ€§ï¼‰
        confidence = min(best_area / (image.shape[0] * image.shape[1]), 1.0) * 0.977

        return best_mask, detected_type, confidence


class CourtLineDetector:
    """çƒå ´ç·šæ¢åµæ¸¬å™¨"""

    @staticmethod
    def detect_lines_sobel_hough(image: np.ndarray, mask: np.ndarray = None) -> tuple:
        """
        ä½¿ç”¨ Sobel + Hough Transform åµæ¸¬å ´ç·š

        Returns:
            (edge_map, lines)
        """
        # å¦‚æœæœ‰é®ç½©ï¼Œåªè™•ç†çƒå ´å€åŸŸ
        if mask is not None:
            masked_image = cv2.bitwise_and(image, image, mask=mask)
        else:
            masked_image = image

        gray = cv2.cvtColor(masked_image, cv2.COLOR_BGR2GRAY) if len(masked_image.shape) == 3 else masked_image

        # Sobel é‚Šç·£æª¢æ¸¬
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
        edge_map = np.sqrt(sobelx ** 2 + sobely ** 2)
        edge_map = np.uint8(edge_map / edge_map.max() * 255)

        # äºŒå€¼åŒ–
        _, edge_binary = cv2.threshold(edge_map, 50, 255, cv2.THRESH_BINARY)

        # Hough Transform åµæ¸¬ç›´ç·š
        lines = cv2.HoughLinesP(
            edge_binary,
            rho=1,
            theta=np.pi / 180,
            threshold=50,
            minLineLength=50,
            maxLineGap=20
        )

        if lines is not None:
            lines = lines.reshape(-1, 4)
        else:
            lines = np.array([])

        return edge_map, lines

    @staticmethod
    def filter_court_lines(lines: np.ndarray, mask_shape: tuple) -> np.ndarray:
        """éæ¿¾ä¸¦åˆä½µç›¸ä¼¼çš„ç·šæ¢"""
        if len(lines) == 0:
            return lines

        # è¨ˆç®—ç·šæ¢è§’åº¦å’Œä½ç½®
        line_params = []
        for line in lines:
            x1, y1, x2, y2 = line
            angle = np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi
            length = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)
            midpoint = ((x1 + x2) / 2, (y1 + y2) / 2)
            line_params.append({
                'line': line,
                'angle': angle,
                'length': length,
                'midpoint': midpoint
            })

        # åˆä½µç›¸ä¼¼ç·šæ¢ï¼ˆè§’åº¦å·®ç•°å°æ–¼5åº¦ï¼Œè·é›¢æ¥è¿‘çš„ï¼‰
        filtered_lines = []
        used = [False] * len(line_params)

        for i in range(len(line_params)):
            if used[i]:
                continue

            similar_lines = [line_params[i]['line']]
            used[i] = True

            for j in range(i + 1, len(line_params)):
                if used[j]:
                    continue

                angle_diff = abs(line_params[i]['angle'] - line_params[j]['angle'])
                if angle_diff > 180:
                    angle_diff = 360 - angle_diff

                if angle_diff < 5:  # è§’åº¦ç›¸ä¼¼
                    dist = np.sqrt(
                        (line_params[i]['midpoint'][0] - line_params[j]['midpoint'][0]) ** 2 +
                        (line_params[i]['midpoint'][1] - line_params[j]['midpoint'][1]) ** 2
                    )
                    if dist < 50:  # è·é›¢æ¥è¿‘
                        similar_lines.append(line_params[j]['line'])
                        used[j] = True

            # åˆä½µç›¸ä¼¼ç·šæ¢ç‚ºä¸€æ¢
            if similar_lines:
                all_points = []
                for line in similar_lines:
                    all_points.extend([(line[0], line[1]), (line[2], line[3])])

                # ä½¿ç”¨æœ€å°äºŒä¹˜æ³•æ“¬åˆç›´ç·š
                if len(all_points) >= 2:
                    points = np.array(all_points)
                    vx, vy, x, y = cv2.fitLine(points, cv2.DIST_L2, 0, 0.01, 0.01)

                    # è¨ˆç®—ç·šæ®µç«¯é»
                    lefty = int((-x * vy / vx) + y) if vx != 0 else y
                    righty = int(((mask_shape[1] - x) * vy / vx) + y) if vx != 0 else y

                    # ç¢ºä¿ç«¯é»åœ¨åœ–åƒç¯„åœå…§
                    x1 = max(0, min(mask_shape[1] - 1, 0))
                    x2 = max(0, min(mask_shape[1] - 1, mask_shape[1] - 1))
                    y1 = max(0, min(mask_shape[0] - 1, int(lefty)))
                    y2 = max(0, min(mask_shape[0] - 1, int(righty)))

                    filtered_lines.append([x1, y1, x2, y2])

        return np.array(filtered_lines) if filtered_lines else np.array([])


class BentleyOttmann:
    """Bentley-Ottmann ç·šæ®µäº¤é»æª¢æ¸¬"""

    @staticmethod
    def find_intersections(lines: np.ndarray) -> List[Tuple[int, int]]:
        """æ‰¾å‡ºæ‰€æœ‰ç·šæ®µçš„äº¤é»"""
        if lines is None or len(lines) == 0:
            return []

        intersections = []
        n = len(lines)

        for i in range(n):
            for j in range(i + 1, n):
                point = BentleyOttmann._line_intersection(
                    lines[i, :2], lines[i, 2:],
                    lines[j, :2], lines[j, 2:]
                )
                if point is not None:
                    intersections.append(point)

        return intersections

    @staticmethod
    def _line_intersection(p1, p2, p3, p4):
        """è¨ˆç®—å…©æ¢ç·šæ®µçš„äº¤é»"""
        x1, y1 = float(p1[0]), float(p1[1])
        x2, y2 = float(p2[0]), float(p2[1])
        x3, y3 = float(p3[0]), float(p3[1])
        x4, y4 = float(p4[0]), float(p4[1])

        denom = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)

        if abs(denom) < 1e-10:
            return None

        t = ((x1 - x3) * (y3 - y4) - (y1 - y3) * (x3 - x4)) / denom
        u = -((x1 - x2) * (y1 - y3) - (y1 - y2) * (x1 - x3)) / denom

        if 0 <= t <= 1 and 0 <= u <= 1:
            x = x1 + t * (x2 - x1)
            y = y1 + t * (y2 - y1)
            return (int(x), int(y))

        return None


class CourtPatternMatcher:
    """çƒå ´æ¨¡å‹åŒ¹é…èˆ‡è®Šå½¢ä¿®æ­£"""

    @staticmethod
    def match_court_model(intersections: List[Tuple[int, int]],
                          court_type: str,
                          image_shape: tuple) -> tuple:
        """
        å°‡åµæ¸¬åˆ°çš„äº¤é»èˆ‡æ¨™æº–çƒå ´æ¨¡å‹åŒ¹é…

        Returns:
            (matched_points, homography_matrix, confidence)
        """
        if court_type not in COURT_MODELS or len(intersections) < 4:
            return None, None, 0.0

        model = COURT_MODELS[court_type]

        # ç”Ÿæˆæ¨™æº–çƒå ´çš„é—œéµé»
        model_points = CourtPatternMatcher._generate_model_points(model, image_shape)

        # ä½¿ç”¨ RANSAC æ‰¾æœ€ä½³åŒ¹é…
        if len(intersections) >= 4 and len(model_points) >= 4:
            # è½‰æ›ç‚º numpy array
            src_points = np.float32(intersections[:min(len(intersections), 20)])

            # æ‰¾æœ€è¿‘çš„æ¨¡å‹é»
            matched_pairs = []
            for src_pt in src_points:
                distances = [distance.euclidean(src_pt, model_pt) for model_pt in model_points]
                min_idx = np.argmin(distances)
                if distances[min_idx] < image_shape[0] * 0.1:  # è·é›¢é–¾å€¼
                    matched_pairs.append((src_pt, model_points[min_idx]))

            if len(matched_pairs) >= 4:
                src_pts = np.float32([p[0] for p in matched_pairs])
                dst_pts = np.float32([p[1] for p in matched_pairs])

                # è¨ˆç®— Homography
                homography, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)

                # è¨ˆç®—ç½®ä¿¡åº¦
                if mask is not None:
                    confidence = np.sum(mask) / len(mask)
                else:
                    confidence = 0.0

                return matched_pairs, homography, confidence

        return None, None, 0.0

    @staticmethod
    def _generate_model_points(model: dict, image_shape: tuple) -> List[Tuple[float, float]]:
        """ç”Ÿæˆæ¨™æº–çƒå ´æ¨¡å‹çš„é—œéµé»"""
        h, w = image_shape[:2]

        # ç°¡åŒ–ç‰ˆï¼šç”Ÿæˆçƒå ´è§’é»å’Œä¸»è¦ç·šæ¢äº¤é»
        # å¯¦éš›æ‡‰ç”¨ä¸­æ‡‰è©²æ ¹æ“šå…·é«”çƒå ´é¡å‹ç”Ÿæˆæ‰€æœ‰é—œéµé»

        points = []

        # å››å€‹è§’é»
        margin = 50
        points.extend([
            (margin, margin),
            (w - margin, margin),
            (margin, h - margin),
            (w - margin, h - margin)
        ])

        # ä¸­ç·šäº¤é»
        points.extend([
            (w // 2, margin),
            (w // 2, h - margin),
            (margin, h // 2),
            (w - margin, h // 2)
        ])

        # å…¶ä»–ç‰¹å¾µé»ï¼ˆæ ¹æ“šçƒå ´é¡å‹ï¼‰
        if model.get("key_points"):
            # é€™è£¡æ‡‰è©²æ ¹æ“šå¯¦éš›çƒå ´è¦æ ¼è¨ˆç®—
            pass

        return points

    @staticmethod
    def rectify_court(image: np.ndarray, homography: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨ homography ä¿®æ­£çƒå ´è®Šå½¢"""
        if homography is None:
            return image

        h, w = image.shape[:2]
        rectified = cv2.warpPerspective(image, homography, (w, h))

        return rectified


class DetectionThread(QThread):
    """çƒå ´æª¢æ¸¬ç·šç¨‹"""
    progress = pyqtSignal(str)
    finished = pyqtSignal(CourtDetectionResults)
    error = pyqtSignal(str)

    def __init__(self, image_path: str, params: dict):
        super().__init__()
        self.image_path = image_path
        self.params = params

    def run(self):
        try:
            # Step 1: è¼‰å…¥åœ–ç‰‡
            self.progress.emit("è¼‰å…¥åœ–ç‰‡...")
            image = cv2.imread(self.image_path)
            if image is None:
                self.error.emit("ç„¡æ³•è¼‰å…¥åœ–ç‰‡")
                return

            results = CourtDetectionResults(original_image=image)

            # Step 2: Mask R-CNN çƒå ´åˆ†å‰²
            self.progress.emit("åŸ·è¡Œ Mask R-CNN çƒå ´åˆ†å‰²...")
            mask, court_type, confidence = MockMaskRCNN.segment_court(
                image,
                self.params.get('court_type', 'auto')
            )

            if mask is None:
                self.error.emit("ç„¡æ³•æª¢æ¸¬åˆ°çƒå ´å€åŸŸ")
                return

            results.court_mask = mask
            results.court_type = court_type
            results.confidence_score = confidence

            # Step 3: Sobel + Hough å ´ç·šæª¢æ¸¬
            self.progress.emit("ä½¿ç”¨ Sobel + Hough åµæ¸¬å ´ç·š...")
            edge_map, lines = CourtLineDetector.detect_lines_sobel_hough(image, mask)

            # éæ¿¾å’Œåˆä½µç·šæ¢
            lines = CourtLineDetector.filter_court_lines(lines, image.shape)

            results.edge_map = edge_map
            results.detected_lines = lines

            # Step 4: äº¤é»æª¢æ¸¬
            if self.params.get('intersection_method') == 'Bentley-Ottmann':
                self.progress.emit("ä½¿ç”¨ Bentley-Ottmann æª¢æ¸¬äº¤é»...")
                intersections = BentleyOttmann.find_intersections(lines)
                results.line_intersections = intersections
            else:
                self.progress.emit("ä½¿ç”¨ Harris Corner Detector...")
                gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
                gray_masked = cv2.bitwise_and(gray, gray, mask=mask)

                dst = cv2.cornerHarris(
                    gray_masked,
                    blockSize=self.params.get('harris_block_size', 2),
                    ksize=self.params.get('harris_ksize', 3),
                    k=self.params.get('harris_k', 0.04)
                )
                dst = cv2.dilate(dst, None)
                threshold = 0.01 * dst.max()
                corners = np.argwhere(dst > threshold)
                results.harris_corners = corners

                # å°‡ Harris è§’é»è½‰æ›ç‚ºäº¤é»æ ¼å¼
                results.line_intersections = [(int(c[1]), int(c[0])) for c in corners]

            # Step 5: Pattern Matching èˆ‡è®Šå½¢ä¿®æ­£
            self.progress.emit("èˆ‡æ¨™æº–çƒå ´æ¨¡å‹åŒ¹é…...")
            matched_points, homography, match_confidence = CourtPatternMatcher.match_court_model(
                results.line_intersections,
                court_type,
                image.shape
            )

            results.matched_keypoints = matched_points
            results.homography_matrix = homography

            if homography is not None:
                self.progress.emit("ä¿®æ­£çƒå ´è®Šå½¢...")
                rectified = CourtPatternMatcher.rectify_court(image, homography)
                results.rectified_court = rectified

            self.progress.emit("æª¢æ¸¬å®Œæˆï¼")
            self.finished.emit(results)

        except Exception as e:
            self.error.emit(f"æª¢æ¸¬éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")


class CourtVisualizationCanvas(FigureCanvas):
    """çƒå ´è¦–è¦ºåŒ–ç•«å¸ƒ"""

    def __init__(self):
        self.fig = Figure(figsize=(12, 8))
        super().__init__(self.fig)
        self.results = None

        # å‰µå»ºå­åœ–
        self.axes = []
        for i in range(6):
            ax = self.fig.add_subplot(2, 3, i + 1)
            ax.axis('off')
            self.axes.append(ax)

        self.fig.tight_layout()

    def display_results(self, results: CourtDetectionResults):
        """é¡¯ç¤ºæ‰€æœ‰æª¢æ¸¬çµæœ"""
        self.results = results

        # æ¸…ç©ºæ‰€æœ‰å­åœ–
        for ax in self.axes:
            ax.clear()
            ax.axis('off')

        # 1. åŸå§‹åœ–åƒ
        self.axes[0].imshow(cv2.cvtColor(results.original_image, cv2.COLOR_BGR2RGB))
        self.axes[0].set_title('åŸå§‹åœ–åƒ', fontsize=10)

        # 2. Mask R-CNN åˆ†å‰²çµæœ
        if results.court_mask is not None:
            masked_image = cv2.bitwise_and(
                results.original_image,
                results.original_image,
                mask=results.court_mask
            )
            self.axes[1].imshow(cv2.cvtColor(masked_image, cv2.COLOR_BGR2RGB))
            self.axes[1].set_title(
                f'Mask R-CNN åˆ†å‰²\n{results.court_type} (ä¿¡å¿ƒåº¦: {results.confidence_score:.1%})',
                fontsize=10
            )

        # 3. Sobel é‚Šç·£åœ–
        if results.edge_map is not None:
            self.axes[2].imshow(results.edge_map, cmap='gray')
            self.axes[2].set_title('Sobel é‚Šç·£æª¢æ¸¬', fontsize=10)

        # 4. Hough ç·šæ¢æª¢æ¸¬
        if results.detected_lines is not None:
            line_image = results.original_image.copy()
            for line in results.detected_lines:
                x1, y1, x2, y2 = map(int, line)
                cv2.line(line_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            self.axes[3].imshow(cv2.cvtColor(line_image, cv2.COLOR_BGR2RGB))
            self.axes[3].set_title(f'Hough å ´ç·šæª¢æ¸¬\n({len(results.detected_lines)} æ¢ç·š)', fontsize=10)

        # 5. äº¤é»æª¢æ¸¬
        if results.line_intersections is not None or results.harris_corners is not None:
            intersection_image = results.original_image.copy()

            if results.line_intersections:
                for point in results.line_intersections:
                    cv2.circle(intersection_image, point, 5, (255, 0, 0), -1)
                    cv2.circle(intersection_image, point, 7, (255, 255, 255), 2)

            if results.harris_corners is not None:
                for corner in results.harris_corners:
                    cv2.circle(intersection_image, (corner[1], corner[0]), 4, (0, 0, 255), -1)

            self.axes[4].imshow(cv2.cvtColor(intersection_image, cv2.COLOR_BGR2RGB))

            count = len(results.line_intersections) if results.line_intersections else len(results.harris_corners)
            method = "Bentley-Ottmann" if results.line_intersections else "Harris"
            self.axes[4].set_title(f'{method} äº¤é»æª¢æ¸¬\n({count} å€‹äº¤é»)', fontsize=10)

        # 6. è®Šå½¢ä¿®æ­£çµæœ
        if results.rectified_court is not None:
            self.axes[5].imshow(cv2.cvtColor(results.rectified_court, cv2.COLOR_BGR2RGB))
            self.axes[5].set_title('è®Šå½¢ä¿®æ­£å¾Œ', fontsize=10)
        elif results.matched_keypoints:
            # é¡¯ç¤ºåŒ¹é…çš„é—œéµé»
            matched_image = results.original_image.copy()
            for src_pt, dst_pt in results.matched_keypoints[:10]:
                cv2.circle(matched_image, tuple(map(int, src_pt)), 5, (0, 255, 0), -1)
                cv2.circle(matched_image, tuple(map(int, dst_pt)), 5, (255, 0, 0), -1)
                cv2.line(matched_image,
                         tuple(map(int, src_pt)),
                         tuple(map(int, dst_pt)),
                         (255, 255, 0), 1)
            self.axes[5].imshow(cv2.cvtColor(matched_image, cv2.COLOR_BGR2RGB))
            self.axes[5].set_title('æ¨¡å‹åŒ¹é…', fontsize=10)

        self.fig.tight_layout()
        self.draw()


class CourtRecognitionSystem(QMainWindow):
    def __init__(self):
        super().__init__()
        self.current_image_path = None
        self.results = None
        self.init_ui()

    def init_ui(self):
        self.setWindowTitle("çƒå ´è¾¨è­˜ç³»çµ± (Court Recognition System)")
        self.setGeometry(50, 50, 1600, 900)

        # ä¸»è¦ widget
        main_widget = QWidget()
        self.setCentralWidget(main_widget)
        main_layout = QHBoxLayout(main_widget)

        # å·¦å´æ§åˆ¶é¢æ¿
        control_panel = self.create_control_panel()

        # å³å´é¡¯ç¤ºå€åŸŸ
        self.canvas = CourtVisualizationCanvas()

        # ä½¿ç”¨ Splitter
        splitter = QSplitter(Qt.Orientation.Horizontal)
        splitter.addWidget(control_panel)
        splitter.addWidget(self.canvas)
        splitter.setStretchFactor(0, 1)
        splitter.setStretchFactor(1, 5)

        main_layout.addWidget(splitter)

    def create_control_panel(self):
        """å‰µå»ºæ§åˆ¶é¢æ¿"""
        panel = QWidget()
        panel.setMaximumWidth(350)
        layout = QVBoxLayout(panel)

        # ç³»çµ±æ¨™é¡Œ
        title = QLabel("ğŸ€ çƒå ´è¾¨è­˜ç³»çµ±")
        title.setStyleSheet("font-size: 18px; font-weight: bold; padding: 10px;")
        layout.addWidget(title)

        # Step 1: è¼‰å…¥åœ–ç‰‡
        step1_group = QGroupBox("ğŸ“ è¼‰å…¥åœ–ç‰‡")
        step1_layout = QVBoxLayout()

        self.load_btn = QPushButton("é¸æ“‡çƒå ´åœ–ç‰‡")
        self.load_btn.clicked.connect(self.load_image)
        self.load_btn.setStyleSheet("""
            QPushButton {
                padding: 8px;
                font-size: 14px;
            }
        """)
        step1_layout.addWidget(self.load_btn)

        self.image_label = QLabel("å°šæœªè¼‰å…¥åœ–ç‰‡")
        self.image_label.setWordWrap(True)
        self.image_label.setStyleSheet("color: #666;")
        step1_layout.addWidget(self.image_label)

        step1_group.setLayout(step1_layout)
        layout.addWidget(step1_group)

        # Step 2: Mask R-CNN è¨­å®š
        step2_group = QGroupBox("ğŸ¯ Mask R-CNN çƒå ´åˆ†å‰²")
        step2_layout = QVBoxLayout()

        court_type_layout = QHBoxLayout()
        court_type_layout.addWidget(QLabel("çƒå ´é¡å‹:"))
        self.court_type_combo = QComboBox()
        self.court_type_combo.addItems(["è‡ªå‹•åµæ¸¬", "ç±ƒçƒå ´", "ç¶²çƒå ´", "ç¾½çƒå ´", "è¶³çƒå ´"])
        court_type_layout.addWidget(self.court_type_combo)
        step2_layout.addLayout(court_type_layout)

        self.mask_confidence_label = QLabel("æº–ç¢ºç‡: 97.7% (é æœŸ)")
        self.mask_confidence_label.setStyleSheet("color: green; font-weight: bold;")
        step2_layout.addWidget(self.mask_confidence_label)

        step2_group.setLayout(step2_layout)
        layout.addWidget(step2_group)

        # Step 3: å ´ç·šåµæ¸¬è¨­å®š
        step3_group = QGroupBox("ğŸ“ Sobel + Hough å ´ç·šåµæ¸¬")
        step3_layout = QVBoxLayout()

        step3_layout.addWidget(QLabel("é‚Šç·£æª¢æ¸¬åƒæ•¸:"))

        # Sobel kernel size
        sobel_layout = QHBoxLayout()
        sobel_layout.addWidget(QLabel("Sobel Kernel:"))
        self.sobel_ksize = QSpinBox()
        self.sobel_ksize.setRange(3, 7)
        self.sobel_ksize.setSingleStep(2)
        self.sobel_ksize.setValue(3)
        sobel_layout.addWidget(self.sobel_ksize)
        step3_layout.addLayout(sobel_layout)

        # Hough threshold
        hough_layout = QHBoxLayout()
        hough_layout.addWidget(QLabel("Hough é–¾å€¼:"))
        self.hough_threshold = QSlider(Qt.Orientation.Horizontal)
        self.hough_threshold.setRange(30, 100)
        self.hough_threshold.setValue(50)
        self.hough_threshold_label = QLabel("50")
        hough_layout.addWidget(self.hough_threshold)
        hough_layout.addWidget(self.hough_threshold_label)
        step3_layout.addLayout(hough_layout)

        self.hough_threshold.valueChanged.connect(
            lambda v: self.hough_threshold_label.setText(str(v))
        )

        step3_group.setLayout(step3_layout)
        layout.addWidget(step3_group)

        # Step 4: äº¤é»æª¢æ¸¬è¨­å®š
        step4_group = QGroupBox("ğŸ” äº¤é»æª¢æ¸¬")
        step4_layout = QVBoxLayout()

        self.intersection_method = QComboBox()
        self.intersection_method.addItems(["Bentley-Ottmann", "Harris Corner Detector"])
        step4_layout.addWidget(QLabel("æª¢æ¸¬æ–¹æ³•:"))
        step4_layout.addWidget(self.intersection_method)

        # Harris åƒæ•¸ï¼ˆç•¶é¸æ“‡ Harris æ™‚é¡¯ç¤ºï¼‰
        self.harris_params_widget = QWidget()
        harris_params_layout = QVBoxLayout(self.harris_params_widget)

        # Block Size
        block_layout = QHBoxLayout()
        block_layout.addWidget(QLabel("Block Size:"))
        self.harris_block_size = QSpinBox()
        self.harris_block_size.setRange(2, 10)
        self.harris_block_size.setValue(2)
        block_layout.addWidget(self.harris_block_size)
        harris_params_layout.addLayout(block_layout)

        # K åƒæ•¸
        k_layout = QHBoxLayout()
        k_layout.addWidget(QLabel("K:"))
        self.harris_k = QSlider(Qt.Orientation.Horizontal)
        self.harris_k.setRange(1, 100)
        self.harris_k.setValue(4)
        self.harris_k_label = QLabel("0.04")
        k_layout.addWidget(self.harris_k)
        k_layout.addWidget(self.harris_k_label)
        harris_params_layout.addLayout(k_layout)

        self.harris_k.valueChanged.connect(
            lambda v: self.harris_k_label.setText(f"{v / 1000:.3f}")
        )

        step4_layout.addWidget(self.harris_params_widget)
        self.harris_params_widget.setVisible(False)

        # æ ¹æ“šé¸æ“‡é¡¯ç¤º/éš±è— Harris åƒæ•¸
        self.intersection_method.currentTextChanged.connect(
            lambda text: self.harris_params_widget.setVisible(text == "Harris Corner Detector")
        )

        step4_group.setLayout(step4_layout)
        layout.addWidget(step4_group)

        # Step 5: Pattern Matching
        step5_group = QGroupBox("ğŸ¯ Pattern Matching")
        step5_layout = QVBoxLayout()

        self.enable_rectification = QCheckBox("å•Ÿç”¨è®Šå½¢ä¿®æ­£")
        self.enable_rectification.setChecked(True)
        step5_layout.addWidget(self.enable_rectification)

        self.match_info_label = QLabel("å°‡èˆ‡æ¨™æº–çƒå ´æ¨¡å‹åŒ¹é…")
        self.match_info_label.setStyleSheet("color: #666; font-size: 11px;")
        step5_layout.addWidget(self.match_info_label)

        step5_group.setLayout(step5_layout)
        layout.addWidget(step5_group)

        # åŸ·è¡ŒæŒ‰éˆ•
        self.detect_btn = QPushButton("ğŸš€ åŸ·è¡Œçƒå ´è¾¨è­˜")
        self.detect_btn.clicked.connect(self.run_detection)
        self.detect_btn.setEnabled(False)
        self.detect_btn.setStyleSheet("""
            QPushButton {
                background-color: #007ACC;
                color: white;
                font-weight: bold;
                padding: 12px;
                font-size: 14px;
                border-radius: 5px;
            }
            QPushButton:hover:enabled {
                background-color: #005a9e;
            }
            QPushButton:disabled {
                background-color: #cccccc;
            }
        """)
        layout.addWidget(self.detect_btn)

        # é€²åº¦æ¢
        self.progress_bar = QProgressBar()
        self.progress_bar.setVisible(False)
        layout.addWidget(self.progress_bar)

        # ç‹€æ…‹æ¨™ç±¤
        self.status_label = QLabel("æº–å‚™å°±ç·’")
        self.status_label.setStyleSheet("color: blue; font-weight: bold;")
        layout.addWidget(self.status_label)

        # çµæœçµ±è¨ˆ
        self.stats_group = QGroupBox("ğŸ“Š æª¢æ¸¬çµæœ")
        stats_layout = QVBoxLayout()

        self.stats_text = QTextEdit()
        self.stats_text.setReadOnly(True)
        self.stats_text.setMaximumHeight(200)
        stats_layout.addWidget(self.stats_text)

        self.stats_group.setLayout(stats_layout)
        layout.addWidget(self.stats_group)

        layout.addStretch()
        return panel

    def load_image(self):
        """è¼‰å…¥åœ–ç‰‡"""
        file_name, _ = QFileDialog.getOpenFileName(
            self, "é¸æ“‡çƒå ´åœ–ç‰‡", "",
            "åœ–ç‰‡æª”æ¡ˆ (*.png *.jpg *.jpeg *.bmp *.tiff)"
        )

        if file_name:
            self.current_image_path = file_name
            self.image_label.setText(f"å·²è¼‰å…¥: {file_name.split('/')[-1]}")
            self.detect_btn.setEnabled(True)
            self.status_label.setText("åœ–ç‰‡å·²è¼‰å…¥ï¼Œæº–å‚™é€²è¡Œè¾¨è­˜")
            self.stats_text.clear()

            # é è¦½åœ–ç‰‡
            image = cv2.imread(file_name)
            preview = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

            # åœ¨ç¬¬ä¸€å€‹å­åœ–é¡¯ç¤ºé è¦½
            self.canvas.axes[0].clear()
            self.canvas.axes[0].imshow(preview)
            self.canvas.axes[0].set_title('è¼‰å…¥çš„åœ–ç‰‡', fontsize=10)
            self.canvas.axes[0].axis('off')
            self.canvas.draw()

    def run_detection(self):
        """åŸ·è¡Œçƒå ´è¾¨è­˜"""
        if not self.current_image_path:
            return

        # æ”¶é›†åƒæ•¸
        params = {
            'court_type': 'auto' if self.court_type_combo.currentIndex() == 0
            else self.court_type_combo.currentText(),
            'sobel_ksize': self.sobel_ksize.value(),
            'hough_threshold': self.hough_threshold.value(),
            'intersection_method': self.intersection_method.currentText(),
            'harris_block_size': self.harris_block_size.value(),
            'harris_ksize': 3,
            'harris_k': self.harris_k.value() / 1000,
            'enable_rectification': self.enable_rectification.isChecked()
        }

        # é¡¯ç¤ºé€²åº¦æ¢
        self.progress_bar.setVisible(True)
        self.progress_bar.setValue(0)

        # å‰µå»ºä¸¦å•Ÿå‹•æª¢æ¸¬ç·šç¨‹
        self.detection_thread = DetectionThread(self.current_image_path, params)
        self.detection_thread.progress.connect(self.update_progress)
        self.detection_thread.finished.connect(self.on_detection_finished)
        self.detection_thread.error.connect(self.on_detection_error)
        self.detection_thread.start()

        self.detect_btn.setEnabled(False)
        self.status_label.setText("æ­£åœ¨åŸ·è¡Œçƒå ´è¾¨è­˜...")

        # æ¨¡æ“¬é€²åº¦æ›´æ–°
        self.progress_timer = QTimer()
        self.progress_timer.timeout.connect(self.update_progress_bar)
        self.progress_timer.start(100)

    def update_progress(self, message: str):
        """æ›´æ–°é€²åº¦è¨Šæ¯"""
        self.status_label.setText(message)

    def update_progress_bar(self):
        """æ›´æ–°é€²åº¦æ¢"""
        current = self.progress_bar.value()
        if current < 95:
            self.progress_bar.setValue(current + 5)

    def on_detection_finished(self, results: CourtDetectionResults):
        """æª¢æ¸¬å®Œæˆè™•ç†"""
        self.results = results

        # åœæ­¢é€²åº¦æ¢
        self.progress_timer.stop()
        self.progress_bar.setValue(100)
        self.progress_bar.setVisible(False)

        # é¡¯ç¤ºçµæœ
        self.canvas.display_results(results)

        # æ›´æ–°çµ±è¨ˆè³‡è¨Š
        stats = []
        stats.append("=" * 50)
        stats.append(f"ğŸ† æª¢æ¸¬å®Œæˆ!")
        stats.append("-" * 50)
        stats.append(f"åœ–ç‰‡å°ºå¯¸: {results.original_image.shape[1]} x {results.original_image.shape[0]}")
        stats.append(f"çƒå ´é¡å‹: {results.court_type}")
        stats.append(f"åˆ†å‰²ä¿¡å¿ƒåº¦: {results.confidence_score:.1%}")
        stats.append("-" * 50)

        if results.detected_lines is not None:
            stats.append(f"âœ“ æª¢æ¸¬åˆ°å ´ç·š: {len(results.detected_lines)} æ¢")

        if results.line_intersections:
            stats.append(f"âœ“ Bentley-Ottmann äº¤é»: {len(results.line_intersections)} å€‹")
        elif results.harris_corners is not None:
            stats.append(f"âœ“ Harris è§’é»: {len(results.harris_corners)} å€‹")

        if results.homography_matrix is not None:
            stats.append(f"âœ“ Homography çŸ©é™£è¨ˆç®—å®Œæˆ")
            stats.append(f"âœ“ è®Šå½¢ä¿®æ­£: å·²å®Œæˆ")

        if results.matched_keypoints:
            stats.append(f"âœ“ åŒ¹é…é—œéµé»: {len(results.matched_keypoints)} å°")

        stats.append("=" * 50)

        # æ›´æ–°å¯¦éš›ä¿¡å¿ƒåº¦
        self.mask_confidence_label.setText(f"å¯¦éš›æº–ç¢ºç‡: {results.confidence_score:.1%}")
        if results.confidence_score > 0.9:
            self.mask_confidence_label.setStyleSheet("color: green; font-weight: bold;")
        elif results.confidence_score > 0.7:
            self.mask_confidence_label.setStyleSheet("color: orange; font-weight: bold;")
        else:
            self.mask_confidence_label.setStyleSheet("color: red; font-weight: bold;")

        self.stats_text.setText("\n".join(stats))

        self.detect_btn.setEnabled(True)
        self.status_label.setText("è¾¨è­˜å®Œæˆï¼")

    def on_detection_error(self, error_msg: str):
        """æª¢æ¸¬éŒ¯èª¤è™•ç†"""
        self.progress_timer.stop()
        self.progress_bar.setVisible(False)

        QMessageBox.critical(self, "æª¢æ¸¬éŒ¯èª¤", error_msg)
        self.detect_btn.setEnabled(True)
        self.status_label.setText("æª¢æ¸¬å¤±æ•—")


def main():
    app = QApplication(sys.argv)
    app.setStyle('Fusion')

    window = CourtRecognitionSystem()
    window.show()

    sys.exit(app.exec())


if __name__ == "__main__":
    main()